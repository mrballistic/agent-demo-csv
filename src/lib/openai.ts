/**
 * OpenAI integration and configuration
 * @fileoverview Core OpenAI client setup, assistant configuration, and utility functions for AI-powered data analysis
 */

import OpenAI from 'openai';

/**
 * OpenAI client instance configured with API key
 * Uses environment variable OPENAI_API_KEY or falls back to demo placeholder
 */
export const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'demo-key-placeholder',
});

/**
 * Configuration for the OpenAI Assistant that performs data analysis
 *
 * The assistant is configured as "Analyst-in-a-Box" with specific instructions for:
 * - CSV data profiling and validation
 * - PII detection and security warnings
 * - Analysis suggestions based on data characteristics
 * - Chart generation with matplotlib
 * - Structured JSON output for parsing results
 *
 * Model Configuration:
 * - Model: gpt-4o (optimized for data analysis tasks)
 * - Temperature: 0.2 (lower for more consistent analytical results)
 * - Tools: Code interpreter enabled for data processing
 */
export const ASSISTANT_CONFIG: OpenAI.Beta.Assistants.AssistantCreateParams = {
  name: 'Analyst-in-a-Box',
  model: 'gpt-4o', // Changed from gpt-4o due to server_error issues
  tools: [{ type: 'code_interpreter' }], // Re-enabled now that streaming issues are resolved
  temperature: 0.2,
  instructions: `You are "Analyst-in-a-Box", a careful data analyst.

Contract:
1) When a CSV is provided, first PROFILE the dataset:
   - rows, columns, dtypes, missing %, 5 sample rows (as a markdown table).
   - Detect likely PII columns (email/phone) and set pii=true/false per column.

2) Then PROPOSE 3–5 concrete analyses tailored to available columns.
   - Mark each suggestion with required columns.

3) When the user picks one, RUN exactly one analysis and produce:
   - A 2–3 line plain-English INSIGHT.
   - A single matplotlib PNG chart saved as /mnt/data/plot.png (readable axes, title, units).
   - If you transform data, save /mnt/data/cleaned.csv.

4) Always print a SINGLE LINE of JSON to stdout as the last line:
   {"manifest":{
      "insight":"...",
      "files":[
        {"path":"/mnt/data/plot.png","type":"image","purpose":"chart"},
        {"path":"/mnt/data/cleaned.csv","type":"file","purpose":"data"}
      ],
      "metadata":{"analysis_type":"trend|top-sku|profile|channel-mix","columns_used":["..."]}
   }}

Rules:
- If the request exceeds MVP scope (multi-segmentation), pick the first segment and state the limitation.
- If required columns are missing, STOP and ask for column mapping.
- Use safe defaults: ISO date parsing, currency formatting, thousands separators.
- Never display raw PII values; aggregate or redact.`,
} as const;

/**
 * Types for parsing OpenAI Assistant output manifests
 */

/**
 * Represents a file generated by the AI assistant
 */
export interface ManifestFile {
  /** File system path where the file was saved */
  path: string;
  /** Type of file generated */
  type: 'image' | 'file';
  /** Purpose/description of the file (e.g., 'chart', 'data', 'export') */
  purpose: string;
}

export interface AnalysisManifest {
  insight: string;
  files: ManifestFile[];
  metadata?: {
    analysis_type?: string;
    columns_used?: string[];
    pii_columns?: string[];
    [key: string]: any;
  };
}

export interface RunResult {
  runId: string;
  threadId: string;
  status: 'queued' | 'in_progress' | 'completed' | 'failed' | 'cancelled';
  manifest?: AnalysisManifest;
  messages?: OpenAI.Beta.Threads.Messages.Message[];
  error?: string;
}

// Assistant Manager class
export class AssistantManager {
  private assistantId: string | null = null;

  constructor(private client: OpenAI = openai) {}

  /**
   * Create or retrieve the assistant
   */
  async createAssistant(): Promise<{ id: string }> {
    if (this.assistantId) {
      return { id: this.assistantId };
    }

    try {
      const assistant =
        await this.client.beta.assistants.create(ASSISTANT_CONFIG);
      this.assistantId = assistant.id;
      return { id: assistant.id };
    } catch (error) {
      throw new Error(
        `Failed to create assistant: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * Reset the assistant (force recreation with new config)
   */
  resetAssistant(): void {
    this.assistantId = null;
  }

  /**
   * Cancel any existing runs on a thread
   */
  async cancelExistingRuns(threadId: string): Promise<boolean> {
    try {
      // Get list of runs for the thread
      const runs = await this.client.beta.threads.runs.list(threadId, {
        limit: 10,
      });

      let allCancelled = true;

      // Cancel any runs that are in progress or queued
      for (const run of runs.data) {
        if (run.status === 'in_progress' || run.status === 'queued') {
          console.log(
            `Canceling existing run ${run.id} with status: ${run.status}`
          );
          try {
            await this.client.beta.threads.runs.cancel(threadId, run.id);
            console.log(`Successfully canceled run ${run.id}`);

            // Wait for the run to actually be canceled - with extended timeout for code interpreter
            let attempts = 0;
            const maxAttempts = 60; // 30 seconds for code interpreter runs
            while (attempts < maxAttempts) {
              const updatedRun = await this.client.beta.threads.runs.retrieve(
                threadId,
                run.id
              );
              if (
                updatedRun.status === 'cancelled' ||
                updatedRun.status === 'failed'
              ) {
                console.log(`Run ${run.id} is now ${updatedRun.status}`);
                break;
              }
              console.log(
                `Waiting for run ${run.id} to finish canceling... (status: ${updatedRun.status})`
              );
              await new Promise(resolve => setTimeout(resolve, 500)); // Wait 500ms
              attempts++;
            }

            // Final check - if still not cancelled after max attempts, mark as failed to cancel
            const finalCheck = await this.client.beta.threads.runs.retrieve(
              threadId,
              run.id
            );
            if (
              finalCheck.status === 'in_progress' ||
              finalCheck.status === 'queued' ||
              finalCheck.status === 'cancelling'
            ) {
              console.warn(
                `Run ${run.id} still ${finalCheck.status} after ${maxAttempts * 500}ms, will attempt new run anyway`
              );
              allCancelled = false;
              continue; // Don't throw, just mark as failed and continue
            }

            // Add a small buffer after successful cancellation
            console.log(
              `Run ${run.id} successfully cancelled, waiting brief moment for OpenAI cleanup...`
            );
            await new Promise(resolve => setTimeout(resolve, 1000)); // 1 second buffer
          } catch (cancelError: any) {
            console.warn(
              `Failed to cancel run ${run.id}:`,
              cancelError?.message || cancelError
            );
            allCancelled = false;
            // Don't throw here - log the warning but continue attempting other runs
          }
        }
      }

      return allCancelled;
    } catch (error) {
      console.warn('Failed to check/cancel existing runs:', error);
      return false; // Return false to indicate cancellation was not fully successful
    }
  }

  /**
   * Create a new thread for conversation
   */
  async createThread(): Promise<{ id: string }> {
    try {
      const thread = await this.client.beta.threads.create();
      return { id: thread.id };
    } catch (error) {
      throw new Error(
        `Failed to create thread: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * Create a message in a thread, optionally with file attachment
   */
  async createMessage(
    threadId: string,
    content: string,
    fileId?: string
  ): Promise<OpenAI.Beta.Threads.Messages.Message> {
    try {
      const messageParams: OpenAI.Beta.Threads.Messages.MessageCreateParams = {
        role: 'user',
        content,
      };

      if (fileId) {
        messageParams.attachments = [
          {
            file_id: fileId,
            tools: [{ type: 'code_interpreter' }],
          },
        ];
      }

      const message = await this.client.beta.threads.messages.create(
        threadId,
        messageParams
      );
      return message;
    } catch (error) {
      throw new Error(
        `Failed to create message: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * Upload a file to OpenAI Files API
   */
  async uploadFile(
    fileContent: Buffer,
    filename: string,
    purpose: 'assistants' | 'fine-tune' = 'assistants'
  ): Promise<OpenAI.Files.FileObject> {
    try {
      // Create a File object from the buffer
      const file = new File([new Uint8Array(fileContent)], filename, {
        type: 'text/csv', // Assume CSV for now, could be made configurable
      });

      const uploadedFile = await this.client.files.create({
        file: file,
        purpose: purpose,
      });

      return uploadedFile;
    } catch (error) {
      throw new Error(
        `Failed to upload file: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * Create and execute a run
   */
  async createRun(
    threadId: string,
    assistantId?: string,
    stream: boolean = false
  ): Promise<OpenAI.Beta.Threads.Runs.Run> {
    try {
      const runAssistantId = assistantId || this.assistantId;
      if (!runAssistantId) {
        throw new Error(
          'No assistant ID available. Call createAssistant() first.'
        );
      }

      const runParams: any = {
        assistant_id: runAssistantId,
        max_prompt_tokens: 1000,
        max_completion_tokens: 1000,
        temperature: 0.2,
      };

      if (stream) {
        runParams.stream = true;
      }

      const run = await this.client.beta.threads.runs.create(
        threadId,
        runParams
      );
      return run;
    } catch (error) {
      throw new Error(
        `Failed to create run: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * Create and stream a run with real-time updates
   */
  async *streamRun(
    threadId: string,
    assistantId?: string
  ): AsyncGenerator<any, void, unknown> {
    try {
      const runAssistantId = assistantId || this.assistantId;
      if (!runAssistantId) {
        throw new Error(
          'No assistant ID available. Call createAssistant() first.'
        );
      }

      // Cancel any existing runs before starting a new one
      const cancellationSuccessful = await this.cancelExistingRuns(threadId);
      if (!cancellationSuccessful) {
        console.warn(
          `Some runs could not be cancelled on thread ${threadId}, but proceeding with new run`
        );
      }

      const stream = await this.client.beta.threads.runs.create(threadId, {
        assistant_id: runAssistantId,
        stream: true,
        max_prompt_tokens: 1000,
        max_completion_tokens: 1000,
        temperature: 0.2,
      });

      for await (const event of stream) {
        yield event;
      }
    } catch (error) {
      throw new Error(
        `Failed to stream run: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * Process streaming events and extract artifacts
   */
  async processStreamingRun(
    threadId: string,
    onEvent: (event: any) => void,
    assistantId?: string
  ): Promise<{ runId: string; manifest?: AnalysisManifest }> {
    let runId = '';
    let finalManifest: AnalysisManifest | undefined;

    try {
      for await (const event of this.streamRun(threadId, assistantId)) {
        // Forward the event to the callback
        onEvent(event);

        // Track run ID
        if (event.event === 'thread.run.created' && event.data?.id) {
          runId = event.data.id;
        }

        // Process completed messages for manifest extraction
        if (
          event.event === 'thread.message.completed' &&
          event.data?.role === 'assistant'
        ) {
          try {
            const messages = await this.getMessages(threadId, 5);
            const manifest = extractManifest(messages);
            if (manifest) {
              finalManifest = manifest;
              // Emit custom artifact event
              onEvent({
                event: 'artifact.created',
                data: {
                  manifest,
                  messageId: event.data.id,
                },
              });
            }
          } catch (error) {
            console.warn('Failed to extract manifest:', error);
          }
        }
      }

      return finalManifest ? { runId, manifest: finalManifest } : { runId };
    } catch (error) {
      throw new Error(
        `Failed to process streaming run: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * Cancel a running analysis
   */
  async cancelRun(
    threadId: string,
    runId: string
  ): Promise<OpenAI.Beta.Threads.Runs.Run> {
    try {
      const cancelledRun = await this.client.beta.threads.runs.cancel(
        threadId,
        runId
      );
      return cancelledRun;
    } catch (error) {
      throw new Error(
        `Failed to cancel run: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * Get messages from a thread
   */
  async getMessages(
    threadId: string,
    limit: number = 10
  ): Promise<OpenAI.Beta.Threads.Messages.Message[]> {
    try {
      const messages = await this.client.beta.threads.messages.list(threadId, {
        order: 'desc',
        limit,
      });
      return messages.data;
    } catch (error) {
      throw new Error(
        `Failed to get messages: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * Get a specific run status
   */
  async getRun(
    threadId: string,
    runId: string
  ): Promise<OpenAI.Beta.Threads.Runs.Run> {
    try {
      const run = await this.client.beta.threads.runs.retrieve(threadId, runId);
      return run;
    } catch (error) {
      throw new Error(
        `Failed to get run: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * Download a file from OpenAI
   */
  async downloadFile(fileId: string): Promise<Buffer> {
    try {
      const response = await this.client.files.content(fileId);
      const buffer = Buffer.from(await response.arrayBuffer());
      return buffer;
    } catch (error) {
      throw new Error(
        `Failed to download file: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }
}

/**
 * Extract manifest from assistant output
 * Parses the last line JSON with fallback to message content
 */
export function extractManifest(
  messages: OpenAI.Beta.Threads.Messages.Message[]
): AnalysisManifest | null {
  // Find the latest assistant message
  const latestAssistantMessage = messages.find(msg => msg.role === 'assistant');

  if (!latestAssistantMessage) {
    return null;
  }

  // Get the text content from the message
  const textContent = latestAssistantMessage.content
    .filter(content => content.type === 'text')
    .map(content => content.text.value)
    .join('\n');

  if (!textContent) {
    return null;
  }

  try {
    // Try to parse the last line as JSON manifest
    const lines = textContent.trim().split(/\r?\n/);
    const lastLine = lines[lines.length - 1];

    if (!lastLine) {
      throw new Error('No content to parse');
    }

    // Try to parse as JSON
    const parsed = JSON.parse(lastLine);

    if (parsed?.manifest) {
      return parsed.manifest as AnalysisManifest;
    }

    // If no manifest property, check if the whole line is a manifest
    if (parsed?.insight && parsed?.files) {
      return parsed as AnalysisManifest;
    }

    // Fallback: create a basic manifest from message content
    return {
      insight: textContent.split('\n')[0] || 'Analysis completed',
      files: [],
      metadata: {
        analysis_type: 'unknown',
        fallback: true,
      },
    };
  } catch (error) {
    // JSON parsing failed, create fallback manifest
    return {
      insight: textContent.split('\n')[0] || 'Analysis completed',
      files: [],
      metadata: {
        analysis_type: 'unknown',
        fallback: true,
        parse_error:
          error instanceof Error ? error.message : 'Unknown parsing error',
      },
    };
  }
}

// Create a singleton instance
export const assistantManager = new AssistantManager();

// Export types for use in other modules
export type { OpenAI } from 'openai';
